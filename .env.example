# OpenAI API Key (required)
OPENAI_API_KEY=your_api_key_here

# Optional: Debug mode for token tracking
DEBUG=true

# Optional: Maximum token budget (default: 1500)
MAX_TOKENS=1500

# Optional: Maximum number of knowledge entries to retrieve (default: 3)
TOP_K_RETRIEVAL=3

# Optional: Budget allocation percentages (defaults: 7% + 10% + 40% + 43% = 100%)
# These determine how MAX_TOKENS is distributed across components
# (Values in brackets show tokens for default MAX_TOKENS=1500)
BUDGET_SAFETY_MARGIN_PCT=7        # Safety buffer for token estimation variance [105 tokens]
BUDGET_SYSTEM_PROMPT_PCT=10       # Agent instructions and knowledge formatting [150 tokens]
BUDGET_KNOWLEDGE_PCT=40           # Retrieved knowledge entries [600 tokens]
BUDGET_CONVERSATION_PCT=43        # Conversation history [645 tokens]

# Optional: Conversation compression strategy (default: prune)
# - prune: Remove oldest messages (FIFO) - Fast, no API cost
# - summarize: Summarize old messages - Preserves context, requires API call
COMPRESSION_STRATEGY=summarize

# Optional: Maximum tokens for summary generation (default: 33% of MAX_TOKENS)
# Used when COMPRESSION_STRATEGY=summarize
# For MAX_TOKENS=1500, 33% = 495 tokens max
SUMMARY_MAX_TOKENS_PCT=33

# Optional: Allow summarization to fall back to pruning (default: true)
# When true: Falls back to pruning if < 4 messages or < 100 tokens
# When false: Always attempts summarization regardless of message count/tokens
ALLOW_SUMMARIZATION_FALLBACK=false

# Optional: Minimum number of recent messages to keep intact (default: 0)
# MIN_RECENT_MESSAGES=0 (no minimum, purely token-budget driven)
# Ensures at least this many recent messages are never summarized
# Works alongside token budget - whichever keeps more messages wins
# Example: MIN_RECENT_MESSAGES=4 ensures the last 4 messages always stay intact
MIN_RECENT_MESSAGES=2
